# -*- coding: utf-8 -*-
"""[HW01] AutoEncoder.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DfKWvgbYOI2C_-Kv8YhfKAML-idSkVaP

# ğŸ“ ê³¼ì œ ì œì¶œ ì •ë³´  

| ğŸ“Œ í•­ëª©  | âœï¸ ì…ë ¥ |
|---------|-------|
| **í•™ê³¼** | `ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€` |
| **í•™ë²ˆ** | `20203084` |
| **ì´ë¦„** | `ì†¡ë‚˜ë‹¨` |

ğŸš¨ ìœ„ ê³¼ì œ ì œì¶œ ì •ë³´ë¥¼ ì •í™•íˆ ê¸°ì…í•˜ì§€ ì•Šìœ¼ë©´ ê°ì ë©ë‹ˆë‹¤.
"""

from google.colab import drive
drive.mount('/content/drive')

"""---

## [HW01] AutoEncoder

ë‹¤ìŒì„ í™•ì¸í•˜ëŠ” ë¦¬í¬íŠ¸ë¥¼ Colab ë…¸íŠ¸ë¶ì„ ì´ìš©í•´ ì‘ì„±í•œë‹¤.

1. ì •ê·œë¶„í¬ë¥¼ í†µí•œ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”ë¥¼ ì§„í–‰í•œ `Linear` layerë¥¼ Xavier ì´ˆê¸°í™”, He ì´ˆê¸°í™” ê¸°ë²•ì„ í†µí•´ ì´ˆê¸°í™”ë¥¼ ì§„í–‰í•œ ë’¤, ê²°ê³¼ì— ëŒ€í•´ ë¶„ì„í•œë‹¤.

2. Autoencoderì˜ encoderë¥¼ ê±°ì³ ë‚˜ì˜¨ representation $z$ë¥¼ groud truth(GT) labelë³„ë¡œ ë‹¤ë¥¸ìƒ‰ì„ ì£¼ì–´ $z$ì˜ ë¶„í¬ë¥¼ ê°€ì‹œí™”í•œë‹¤.

3. $z$ì˜ ë¶„í¬ë¥¼ ë³´ê³  encoderê°€ labelë³„ë¡œ discriminativeí•œ representationì„ ë§Œë“¤ì–´ë‚´ëŠ”ì§€ í™•ì¸í•œë‹¤.

4. ë§Œì¼ discriminativeí•˜ì§€ ì•Šë‹¤ë©´, autoencoderê°€ discriminativeí•œ representation $z$ë¥¼ í•™ìŠµí•˜ë„ë¡ $z$ì˜ ì°¨ì›ì„ ë°”ê¿”ê°€ë©´ì„œ ì‹¤í—˜í•´ë³¸ë‹¤.

5. $z$ ê³µê°„ì˜ ì„ì˜ì˜ ìœ„ì¹˜ë¥¼ samplingí•œ í›„, í•™ìŠµëœ decoderì˜ ì…ë ¥ìœ¼ë¡œ ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ generative modelì„ êµ¬ì¶•í•œë‹¤. ì˜ë¯¸ìˆê²Œ ë§Œë“¤ì–´ì§„ ì´ë¯¸ì§€ëŠ” ì–´ë–¤ íŠ¹ì§•ì„ ê°–ê³  ìˆëŠ”ì§€ ë…¼ì˜í•œë‹¤.

---

# ì˜¤í† ì¸ì½”ë” (Pytorch)
Pytorchì—ì„œ ì œê³µí•˜ëŠ” ê³ ìˆ˜ì¤€ APIë¥¼ ì´ìš©í•´, ì˜¤í† ì¸ì½”ë”(autoencoder)ë¥¼ êµ¬í˜„í•œë‹¤.

ì°¸ê³ ë¬¸í—Œ
* [Pytorch tutorial](https://tutorials.pytorch.kr/)
* [Dive into Deep learning](https://d2l.ai/)


ì£¼ì˜ì‚¬í•­
* Colabì—ì„œ ì½”ë“œì— ì´ìƒì´ ì—†ìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ê²°ê³¼ê°€ ì œëŒ€ë¡œ ë‚˜ì˜¤ì§€ ì•Šì„ ê²½ìš°, 'ëŸ°íƒ€ì„ ë‹¤ì‹œ ì‹œì‘...'ì„ í•´ë³´ë„ë¡ í•œë‹¤.'


## Deep Neural Network ê¸°ì´ˆ
ë‹¤ìŒ ë¹„ë””ì˜¤ë¥¼ ë³´ê³  ì‹¬ì¸µì‹ ê²½ë§(deep neural network) ê¸°ë°˜ ë”¥ëŸ¬ë‹ ê¸°ë²•ì€ ì´í•´í•˜ë„ë¡ í•œë‹¤.
* [ì‹ ê²½ë§ì´ë€ ë¬´ì—‡ì¸ê°€? | 1ì¥.ë”¥ëŸ¬ë‹ì— ê´€í•˜ì—¬ (3Blue1Brown)](https://youtu.be/aircAruvnKk)
* [ê²½ì‚¬ í•˜ê°•, ì‹ ê²½ ë„¤íŠ¸ì›Œí¬ê°€ í•™ìŠµí•˜ëŠ” ë°©ë²• | ì‹¬ì¸µ í•™ìŠµ, 2ì¥ (3Blue1Brown)](https://youtu.be/IHZwWFHWa-w)
* [What is backpropagation really doing? | Deep learning, chapter 3 (3Blue1Brown)](https://youtu.be/Ilg3gGewQ5U)
* [Backpropagation calculus | Deep learning, chapter 4 (3Blue1Brown)](https://youtu.be/tIeHLnjs5U8)

## í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸
"""

import sys
import time
import numpy as np
import matplotlib.pyplot as plt

import torch                                      # íŒŒì´í† ì¹˜ ì„í¬íŠ¸
import torch.nn as nn                             # nn ëª¨ë“ˆ ì„í¬íŠ¸
import torch.nn.functional as F

import torchvision                                # torchvision ì„í¬íŠ¸
import torchvision.utils as utils
import torchvision.transforms as transforms       # numpy ì´ë¯¸ì§€ì—ì„œ tensor ì´ë¯¸ì§€ë¡œ ë³€ê²½í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ
import torchvision.datasets as datasets           # pytorchì— ë‚´ì¥ëœ datasetì„ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ëª¨ë“ˆ

from tqdm import tqdm

print("Python:", sys.version)
print("Numpy:", np.__version__)

print("Torch: ", torch.__version__)               # íŒŒì´í† ì¹˜ ë²„ì „ì„ í™•ì¸í•˜ë„ë¡ í•œë‹¤.
print("Torchvision: ", torchvision.__version__)   # í† ì¹˜ë¹„ì „ ë²„ì „ì„ í™•ì¸í•˜ë„ë¡ í•œë‹¤.

"""## GPU ë””ë°”ì´ìŠ¤ ì„ íƒ ë° í™•ì¸"""

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
use_cuda = torch.cuda.is_available()
print(use_cuda)
if use_cuda:
  print(torch.cuda.get_device_name(0))

"""## Hyperparameter ì„¤ì •
* batch size, learning rate, epochì„ ì„¤ì •
"""

batch_size    = 100
learning_rate = 0.001
num_epochs    = 10

"""## MNIST ë°ì´í„°ì…‹ ë„ìš°ê¸°
![MnistExamples.png](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)
* mnist ë°ì´í„°ì…‹ì€ ìˆ«ì(digit) ì†ê¸€ì”¨ ë°ì´í„°ì…‹ì´ë‹¤.
* 60,000ê°œì˜ íŠ¸ë ˆì´ë‹ ë°ì´í„°ì™€ 10,000ê°œì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤.
* LeCunì´ ìì‹ ì˜ ì—°êµ¬ì—ì„œ í™œìš©í•˜ê³  ë°°í¬í•œ ë°ì´í„°ì…‹ì´ ìˆìœ¼ë‚˜ ìµœê·¼ ë³´í¸ì ìœ¼ë¡œ ë§ì´ í™œìš©í•˜ê¸° ë•Œë¬¸ì— í…ì„œí”Œë¡œìš°ë‚˜ íŒŒì´í† ì¹˜ ë“±ì—ì„œ built-in ë°ì´í„°ì…‹ì˜ í˜•íƒœë¡œ ì œê³µí•´ ì£¼ê¸°ë„ í•œë‹¤.  

### MNIST ì´ë¯¸ì§€ ë°ì´í„°
* MNIST ë°ì´í„°ì…‹ì€ ì—¬ëŸ¬ ë²„ì ¼ì´ ìˆìœ¼ë‚˜, ì—¬ê¸°ì„œëŠ” ì´ë¥¼ íŒŒì´í† ì¹˜ì— ë§ê²Œ ì •ë¦¬í•˜ì—¬ torchvision.datasetsì—ì„œ built-inìœ¼ë¡œ ì œê³µí•˜ëŠ” ë°ì´í„°ì…‹ì„ ì“°ë„ë¡ í•˜ê² ë‹¤. ([link](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html))
  + (PIL image, integer label)ë¡œ êµ¬ì„±ëœ ë°ì´í„°ë¥¼ ì œê³µ.
  + PIL imageëŠ” ê° í”½ì…€ì´ [0, 255] ì‚¬ì´ê°’ìœ¼ë¡œ êµ¬ì„±ëœ H x W x C í¬ê¸°ì˜ ì´ë¯¸ì§€ì´ë‹¤.
* ë‰´ëŸ´ë„·ì˜ ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ìœ„í•´ í”½ì…€ê°’ì´ 0 ê·¼ì²˜ì— ìˆëŠ” ì‘ì€ ì‹¤ìˆ˜ê°’ì„ ê°€ì§€ë„ë¡ ë‹¤ìŒê³¼ ê°™ì´ ë³€í™˜í•œë‹¤.
  + ToTensor(): [0, 255] ì‚¬ì´ ê°’ì„ [0.0, 1.0] ì‚¬ì´ê°’ìœ¼ë¡œ ë³€í™”ì‹œí‚´ê³¼ ë™ì‹œì— C x H x W í˜•íƒœë¡œ ë³€í™˜ì‹œí‚¨ë‹¤.
"""

import torchvision.transforms as transforms
from torchvision.datasets import MNIST

# download path ì •ì˜
download_root = './MNIST_DATASET'


# PIL image (H x W x C) -> torch tensor (C x H x W) and
# [0, 255] -> [0.0, 1.0]
mnist_transform = transforms.Compose([
    transforms.ToTensor(),
])

train_dataset = MNIST(download_root,
                      transform=mnist_transform,
                      train=True,
                      download=True)

test_dataset = MNIST(download_root,
                     transform=mnist_transform,
                     train=False,
                     download=False)

"""## ë°ì´í„°ì…‹ í™•ì¸
ë°ì´í„°ì…‹ì„ ë¡œë”©í•œ í›„ **ë°ì´í„°ì…‹ êµ¬ì„±**ì´ ì–´ë–»ê²Œ ë˜ì–´ ìˆëŠ”ì§€ **ë°˜ë“œì‹œ í™•ì¸**í•˜ëŠ” ìŠµê´€ì„ ê°€ì§€ë„ë¡ í•œë‹¤.

torchvision.datasets.MNIST ë°ì´í„°ì…‹ì˜ ê° ë°ì´í„°ëŠ” (ì´ë¯¸ì§€, ë ˆì´ë¸”)ë¡œ êµ¬ì„±ëœ íŠœí”Œì´ë‹¤.

ë‹¤ìŒì€ MNIST ë°ì´í„°ì…‹ì— ìˆëŠ” ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ì— ëŒ€í•œ ê°ì¢… ì •ë³´ë¥¼ í™•ì¸í•˜ëŠ” ì½”ë“œì´ë‹¤.

í•´ë‹¹ ì½”ë“œë¥¼ í†µí•´ ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
* train_datasetì˜ ê¸¸ì´ëŠ” 60,000ì´ë‹¤.
* test_datasetì˜ ê¸¸ì´ëŠ” 10,000ì´ë‹¤.

### MNIST ì´ë¯¸ì§€ ë°ì´í„°
* ê° ì´ë¯¸ì§€ëŠ” C X H x W ìˆœì„œë¡œ êµ¬ì„±ëœ [1, 28, 28] ëª¨ì–‘ì˜ í…ì„œë¡œ ë¡œë”©ë˜ì—ˆë‹¤.
* ê° ì´ë¯¸ì§€ í”½ì…€ê°’ì€ ToTensor() ë³€í™˜ì„ í†µí•´ [0.0, 1.0] ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆë‹¤.
* ê° ì´ë¯¸ì§€ í”½ì…€ê°’ì€ `torch.float32` íƒ€ì…ì´ë‹¤.
* ê° ë ˆì´ë¸” ê°’ì˜ íƒ€ì…ì€ íŒŒì´ì¬ `int` í˜•ì´ë‹¤.

### MNIST ë¼ë²¨ ë°ì´í„°
* ê° ë ˆì´ë¸” ê°’ì€ [0, 9] ì‚¬ì´ì˜ íŒŒì´ì¬ `int`í˜•ì´ë‹¤.
"""

def print_MNIST_dataset_info(dataset):
  print(">>> dataset length: ", len(dataset))
  print(">>> type of each data: ", type(dataset[0]))
  first_img, first_label = dataset[0]
  print(">>> image shape: ", first_img.shape)
  print(">>> image dtype: ", first_img.dtype)
  print(">>> image pixel min-value: ", first_img.min())
  print(">>> image pixel max-value: ", first_img.max())
  print(">>> label data type: ", type(first_label))

print("train dataset")
print_MNIST_dataset_info(train_dataset)

print("test dataset")
print_MNIST_dataset_info(test_dataset)

"""## MNIST DataLoader ì •ì˜

[íŒŒì´í† ì¹˜ ë°ì´í„°ë¡œë”](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)ëŠ” ë°ì´í„°ì…‹ì„ ë°°ì¹˜ë‹¨ìœ„ë¡œ ë¬¶ì–´ ìˆœíšŒ(iteration)í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

ì•„ë˜ ì½”ë“œëŠ” ë°ì´í„°ì…‹ì— ëŒ€í•œ ë°ì´í„°ë¡œë”ë¥¼ ë§Œë“¤ê³ , ê° ë°°ì¹˜ê°€ ì–´ë–¤ í…ì„œ í˜•íƒœë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ì½”ë“œì´ë‹¤.
* ë°ì´í„°ë¡œë”ì—ì„œëŠ” ì´ë¯¸ì§€ë“¤ì´ ë°°ì¹˜ë‹¨ìœ„ë¡œ ë¬¶ì˜€ê¸° ë•Œë¬¸ì—, B x C x H x W ëª¨ì–‘(shape)ì˜ í…ì„œì´ë©°, ë°ì´í„°íƒ€ì…(dtype)ì€ `torch.float32`ê°€ ë˜ì—ˆìŒì„ í™•ì¸í•˜ì.
* ë°ì´í„°ë¡œë”ì—ì„œëŠ” ë ˆì´ë¸”ë“¤ì´ ë°°ì¹˜ë‹¨ìœ„ë¡œ ë¬¶ì˜€ê¸° ë•Œë¬¸ì—, B ëª¨ì–‘(shape)ì˜ í…ì„œì´ë©°, ë°ì´í„°íƒ€ì…(dtype)ì€ `torch.int64`ê°€ ë˜ì—ˆìŒì„ í™•ì¸í•˜ì.

train_datasetê³¼ test_datasetì€ ë™ì¼ í˜•íƒœì´ë¯€ë¡œ, train_datasetì˜ ë°ì´í„°ë¡œë”ì— ëŒ€í•´ì„œë§Œ í™•ì¸í•˜ì˜€ë‹¤.

"""

from torch.utils.data import DataLoader

# dataloader ì •ì˜
train_loader = DataLoader(dataset=train_dataset,
                          batch_size=batch_size,
                          shuffle=True)

test_loader = DataLoader(dataset=test_dataset,
                         batch_size=batch_size,
                         shuffle=False)

def print_MNIST_data_loader_info(data_loader):
  print(">>> dataset length: ", len(data_loader))
  print(">>> batch_size: ", data_loader.batch_size)
  batch_images, batch_labels = next(iter(train_loader))
  # batch sizeë¡œ ë¬¶ì€ data ì´ë¯¸ì§€ì˜ í˜•íƒœ í™•ì¸
  print(">>> batch_images type", type(batch_images))
  print(">>> batch_images shape", batch_images.shape)
  print(">>> batch_images dtype", batch_images.dtype)

print("train dataset")
print_MNIST_data_loader_info(train_loader)

print("test dataset")
print_MNIST_data_loader_info(test_loader)

"""### ì²«ë²ˆì§¸ ë°°ì¹˜ì˜ ì²«ë²ˆì§¸ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸” í™•ì¸
ì²« ì´ë¯¸ì§€ì™€ í•´ë‹¹ ë ˆì´ë¸”ì„ ì°ì–´ì„œ í™•ì¸í•´ ë³´ì.

C x H x W ì´ë¯¸ì§€ ì •ë³´ê°€ ë³´ê´€ëœ íŒŒì´í† ì¹˜ í…ì„œë¥¼ H x W x C í˜•íƒœì˜ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜ì‹œí‚¤ëŠ” í¸ë¦¬í•œ ë°©ë²•ì€ `to_pil_images` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” í”½ì…€ê°’ì´ [0.0, 1.0] ê°’ìœ¼ë¡œ normalizeë˜ì–´ ìˆìœ¼ë¯€ë¡œ, `to_pil_images` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë©´ [0, 255] ê°’ìœ¼ë¡œ ë³€í™˜ëœë‹¤.
"""

from torchvision.transforms.functional import to_pil_image
import matplotlib.pyplot as plt

# ì²«ë²ˆì§¸ ì´ë¯¸ì§€ í•œì¥ì— ëŒ€í•œ í™•ì¸
batch_images, batch_labels = next(iter(train_loader))

img = batch_images[0]

plt.figure()
plt.imshow(to_pil_image(img), cmap='gray')

"""## ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ ì„¤ê³„
* ì¸ì½”ë” ëª¨ë¸: `torch.nn.Sequential` ëª¨ë“ˆë¡œ ëª¨ë¸ë¡œ ì„¤ê³„
  + InputLayerë¡œ (1,28,28) ì˜ìƒì„ ë°›ê³ , Linear ë ˆì´ì–´ë¥¼ ì—¬ëŸ¿ í†µê³¼ì‹œí‚¨ í›„, ì¶œë ¥ìœ¼ë¡œ n_dimì°¨ì› ë²¡í„°ê°€ ë‚˜ì˜¤ë„ë¡ í•¨.
* ë””ì½”ë” ëª¨ë¸: `torch.nn.Sequential` ëª¨ë“ˆë¡œ ëª¨ë¸ë¡œ ì„¤ê³„
  + InputLayerì—ì„œ n_dimì°¨ì› ë²¡í„°ë¥¼ ë°›ê³ , Linear ë ˆì´ì–´ë¥¼ ì—¬ëŸ¿ í†µê³¼ì‹œí‚¨ í›„, ì¶œë ¥ìœ¼ë¡œ (1,28,28) ì˜ìƒì´ ë‚˜ì˜¤ë„ë¡ í•¨.
* ì˜¤í† ì¸ì½”ë” ëª¨ë¸: ì¸ì½”ë”, ë””ì½”ë”ë¥¼ ê²°í•©í•˜ì—¬ ì„¤ê³„

ì ì¬ ë²¡í„°(latent vector) $z$ì˜ í¬ê¸° ì„¤ì •
ì—¬ê¸°ì„œëŠ” n_dimì„ ìš°ì„  2ë¡œ ì„¤ì •í•œë‹¤.
* ì¦‰, n_dim=2
"""

n_dim = 2

"""ì¸ì½”ë” ëª¨ë¸ ì •ì˜
* (1, 28, 28) ì˜ìƒì„ ì…ë ¥ìœ¼ë¡œ ë°›ë„ë¡ ì…ë ¥ ë ˆì´ì–´ ì •ì˜
* Flattenìœ¼ë¡œ ì…ë ¥ í…ì„œë¥¼ 784-vectorë¡œ ë²¡í„°ë¼ì´ì¦ˆ
* Fully connected layerë¡œ 784 > 256 > 128 > 32 > n_dim ë¡œ ì°¨ì› ì¶•ì†Œ
"""

enc = nn.Sequential(
  nn.Flatten(),    # 784 = 1 x 28 x 28
  nn.Linear(784, 256),
  nn.ReLU(),
  nn.Linear(256, 128),
  nn.ReLU(),
  nn.Linear(128, 32),
  nn.ReLU(),
  nn.Linear(32, n_dim)
)

enc = enc.to(device)

print(enc)

"""ë””ì½”ë” ëª¨ë¸ ì •ì˜
* Fully connected layeyë¡œ n_dim > 32 > 128 > 256 > 784ë¡œ ì°¨ì› í™•ëŒ€
* 784-vectorë¥¼ Reshapeì„ í†µí•´ (28, 28)ì˜ í…ì„œë¡œ ë³€í™˜
"""

dec = nn.Sequential(
    nn.Linear(n_dim, 32),
    nn.ReLU(),
    nn.Linear(32, 256),
    nn.ReLU(),
    nn.Linear(256, 784),
    nn.Unflatten(1, torch.Size([1, 28, 28])),
    nn.Sigmoid(),
)

dec = dec.to(device)

print(dec)

"""AutoEncoder ëª¨ë¸ ì •ì˜
* (1, 28, 28) ì˜ìƒì„ ì…ë ¥ìœ¼ë¡œ ë°›ë„ë¡ ì…ë ¥ ë ˆì´ì–´ ì •ì˜
* ì…ë ¥ ë ˆì´ì–´ > ì¸ì½”ë” > ë””ì½”ë”ë¡œ êµ¬ì„±
* (1, 28, 28) ì˜ìƒì´ ì¶œë ¥ë˜ë¡œë¡ ì•„ì›ƒí’‹ ë ˆì´ì–´ ì •ì˜
"""

ae = nn.Sequential(
    enc,
    dec,
)

ae = ae.to(device)

print(ae)

"""## íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”

## TODO

1. encoder, decoder ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì—¬ `Xavier` ë˜ëŠ” `He Initialization`ì„ ì ìš©í•˜ì—¬ íŒŒë¼ë¯¸í„°ë¥¼ ì´ˆê¸°í™”í•œ í›„ í•™ìŠµì„ ì§„í–‰í•´ë³¸ë‹¤. [Xavier, He initialization ì„¤ëª…](https://reniew.github.io/13/)
  * íŒíŠ¸: `nn.init()`ëª¨ë“ˆì„ ì‚´í´ë³¸ë‹¤.

2. ê²°ê³¼ì— ëŒ€í•œ ë¶„ì„ì„ ì‘ì„±í•œë‹¤.
"""

import torch.nn as nn

n_dim = 2
class Encoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.enc = nn.Sequential(
            nn.Flatten(),               # 784 = 1 x 28 x 28
            nn.Linear(784, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 32),
            nn.ReLU(),
            nn.Linear(32, n_dim)
        )

    def forward(self, x):
        return self.enc(x)

class Decoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.layers = nn.Sequential(
          nn.Linear(n_dim, 32),
          nn.ReLU(),
          nn.Linear(32, 256),
          nn.ReLU(),
          nn.Linear(256, 784),
          nn.Unflatten(1, torch.Size([1, 28, 28])),
          nn.Sigmoid(),
        )

    def forward(self, z):
        return self.layers(z)


class AutoEncoder(nn.Module):
    def __init__(self, encoder, decoder):
        super().__init__()
        self.encoder = encoder
        self.decoder = decoder

    def forward(self, x):
        z = self.encoder(x)
        out = self.decoder(z)
        return out

## Xavier initialization ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”
def initialize_weights_xavier(m):
  if isinstance(m, nn.Linear):
      nn.init.xavier_uniform_(m.weight)
      nn.init.constant_(m.bias, 0)

def initialize_weights_xavier_n(m):
  if isinstance(m, nn.Linear):
      nn.init.xavier_normal_(m.weight)
      nn.init.constant_(m.bias, 0)

# weight ìˆ˜ì§‘
def get_weight_list(model):
  weights_list = []
  for layer in model.modules():
    if isinstance(layer, nn.Linear):
      weights = layer.weight.data.cpu().flatten().numpy()
      weights_list.append(weights)
  return weights_list

# weight ì‹œê°í™” í•¨ìˆ˜
def plot_weight_list(weights_list, title="Xavier Weights"):
    plt.figure(figsize=(len(weights_list) * 3, 4))
    for i, weights in enumerate(weights_list):
        plt.subplot(1, len(weights_list), i+1)
        plt.hist(weights, bins=50, density=True)
        plt.title(f"Layer {i+1}")
        plt.xticks([])
        plt.yticks([])
    plt.suptitle(title)
    plt.tight_layout()
    plt.show()

# í†µê³„ ì¶œë ¥ í•¨ìˆ˜
def print_weight_stats(weights_list):
    for i, w in enumerate(weights_list):
        print(f"[Layer {i+1}] mean: {np.mean(w):.4f}, std: {np.std(w):.4f}, min: {np.min(w):.4f}, max: {np.max(w):.4f}")

# Xavier Uniform ì´ˆê¸°í™”
encoder_xavier_u = Encoder()
encoder_xavier_u.apply(initialize_weights_xavier)

weights_xavier_u = get_weight_list(encoder_xavier_u)
plot_weight_list(weights_xavier_u, "Xavier Initialization - Uniform")
print_weight_stats(weights_xavier_u)

# Xavier Normal ì´ˆê¸°í™”
encoder_xavier_n = Encoder()
encoder_xavier_n.apply(initialize_weights_xavier_n)

weights_xavier_n = get_weight_list(encoder_xavier_n)
plot_weight_list(weights_xavier_n, "Xavier Initialization - Normal")
print_weight_stats(weights_xavier_n)

## He initialization ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” (reluì— ì í•©)
def initialize_weights_he(m):
  if isinstance(m, nn.Linear):
      nn.init.kaiming_uniform_(m.weight, nonlinearity = 'relu')
      nn.init.constant_(m.bias, 0)

def initialize_weights_he_n(m):
  if isinstance(m, nn.Linear):
      nn.init.kaiming_normal_(m.weight, nonlinearity = 'relu')
      nn.init.constant_(m.bias, 0)

# weight ìˆ˜ì§‘
def get_weight_list(model):
  weights_list = []
  for layer in model.modules():
    if isinstance(layer, nn.Linear):
      weights = layer.weight.data.cpu().flatten().numpy()
      weights_list.append(weights)
  return weights_list

# weight ì‹œê°í™” í•¨ìˆ˜
def plot_weight_list(weights_list, title="He Weights"):
    plt.figure(figsize=(len(weights_list) * 3, 4))
    for i, weights in enumerate(weights_list):
        plt.subplot(1, len(weights_list), i+1)
        plt.hist(weights, bins=50, density=True)
        plt.title(f"Layer {i+1}")
        plt.xticks([])
        plt.yticks([])
    plt.suptitle(title)
    plt.tight_layout()
    plt.show()

# í†µê³„ ì¶œë ¥ í•¨ìˆ˜
def print_weight_stats(weights_list):
    for i, w in enumerate(weights_list):
        print(f"[Layer {i+1}] mean: {np.mean(w):.4f}, std: {np.std(w):.4f}, min: {np.min(w):.4f}, max: {np.max(w):.4f}")

# He Uniform ì´ˆê¸°í™”
encoder_he_u = Encoder()
encoder_he_u.apply(initialize_weights_he)

weights_he_u = get_weight_list(encoder_he_u)
plot_weight_list(weights_he_u, "He Initialization - Uniform")
print_weight_stats(weights_he_u)

# He Normal ì´ˆê¸°í™”
encoder_he_n = Encoder()
encoder_he_n.apply(initialize_weights_he_n)

weights_he_n = get_weight_list(encoder_he_n)
plot_weight_list(weights_he_n, "He Initialization - Normal")
print_weight_stats(weights_he_n)

"""## ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ êµ¬ì¡° í™•ì¸

ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì…ì¶œë ¥ êµ¬ì¡°ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ í™•ì¸í•œë‹¤.  ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ì‚¬í•­ì€ ë‹¤ìŒì„ í™•ì¸í•˜ëŠ” ê²ƒì´ë‹¤.

1. ë ˆì´ì–´ì˜ ì—°ê²°êµ¬ì¡°,  
2. ë ˆì´ì–´ë³„ ì…ì¶œë ¥ í…ì„œì˜ ì°¨ì›,
3. í•™ìŠµí•  íŒŒë¼ë©”í„° ê°œìˆ˜
"""

!pip install torchsummary

#encoderì— he ì´ˆê¸°í™” ì ìš©
encoder = encoder_he_u
ae = AutoEncoder(encoder, dec)
ae = ae.to(device)

from torchsummary import summary

summary(ae, (1,28,28))

"""## í›ˆë ¨ ì „, ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ì„ í•¨ìˆ˜ë¡œì„œ í™œìš©
* AutoEncoder aeë¥¼ ëª¨ë¸ë¡œ êµ¬ì„±í–ˆê¸° ë•Œë¬¸ì—, ì§€ê¸ˆë¶€í„° í•¨ìˆ˜ë¡œì„œ í™œìš© ê°€ëŠ¥
  + ë‹¨, ae í•¨ìˆ˜ëŠ” batch ë‹¨ìœ„ë¡œ ìˆ˜í–‰ë¨ì„ ëª…ì‹¬í•  ê²ƒ.  
    - ë‹¨ìˆœíˆ, (1, 28, 28) -> ae -> (1, 28, 28)ë¡œ ë™ì‘í•˜ì§€ ì•Šê³ ,
    - batch ë‹¨ìœ„ë¡œ (?, 1, 28, 28) -> ae -> (?, 1, 28, 28)ë¡œ ë³‘ë ¬ì²˜ë¦¬ë¨.
* ì§€ê¸ˆì€ í›ˆë ¨ ì „ ë„¤íŠ¸ì›ì´ê¸° ë•Œë¬¸ì— í•¨ìˆ˜ë¡œì„œëŠ” ì‘ë™í•˜ì§€ë§Œ ë…¸ì´ì¦ˆ ì¶œë ¥ë§Œ ë‚˜ì˜¬ ë¿, ì •ìƒì ì¸ ì¶œë ¥ì´ ë‚˜ì˜¤ëŠ” í•¨ìˆ˜ë¡œ ë™ì‘í•˜ì§€ ì•ŠìŒ.
"""

import matplotlib.pyplot as plt
from torchvision.transforms.functional import to_pil_image
import ipywidgets as widgets

print("He ì´ˆê¸°í™” ì ìš©")

def train_dataset_imshow(idx):
  (image, label) = train_dataset[idx]
  print('GT label:', label)

  X      = torch.unsqueeze(image, 0).to(device) # batch size = 1
  Y_pred = ae(X)

  input_img  = to_pil_image(X.squeeze())
  output_img = to_pil_image(Y_pred.squeeze())

  plt.subplot(121)
  plt.imshow(input_img, cmap='gray')

  plt.subplot(122)
  plt.imshow(output_img, cmap='gray')

  plt.show()

widgets.interact(train_dataset_imshow, idx=widgets.IntSlider(min=0, max=len(train_dataset)-1, continuous_update=False))

"""## Optimizer, loss í•¨ìˆ˜ ì„¤ì •
í•™ìŠµê³¼ì •ì—ì„œ ì‚¬ìš©í•  optimizer, loss í•¨ìˆ˜ë¥¼ ì„¤ì •í•œë‹¤.
* [optim module](https://pytorch.org/docs/stable/optim.html) ì°¸ê³ <br/>
optimizier ì´ë¡ ì  í•™ìŠµ: [www](https://brunch.co.kr/@chris-song/50)<br/>
optimizer: torch.optim ëª¨ë“ˆ ë‚´ì˜  í•¨ìˆ˜ë“¤ì„ ë‹¤ìŒì˜ ì˜ˆì•½ì–´ë¡œ ì“¸ ìˆ˜ ìˆë‹¤.
  + sgd = SGD
  + rmsprop = RMSprop
  + adagrad = Adagrad
  + adadelta = Adadelta
  + adam = Adam
  + adamax = Adamax
* [nn module](https://pytorch.org/docs/stable/nn.html) ì°¸ê³  <br/>
loss:  torch.nn ëª¨ë“ˆ ë‚´ì˜  í•¨ìˆ˜ë“¤ì„ ë‹¤ìŒì˜ ì˜ˆì•½ì–´ë¡œ ì“¸ ìˆ˜ ìˆë‹¤.
  + mse = MSELoss = mean_squared_error
  + mae = L1Loss = mean_absolute_error
  + kld = KLDivLoss = kullback_leibler_divergence
  + crossentropy = CrossEntropyLoss
"""

# optimizer,loss ì„¤ì •
optimizer = torch.optim.Adam(ae.parameters(), lr=learning_rate)
criterion = nn.MSELoss()

"""## ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ

pytorchì—ì„œëŠ” tensorflowê¸°ë°˜ ì½”ë“œì™€ëŠ” ë‹¬ë¦¬ `fit()` í•¨ìˆ˜ë¥¼ ì§ì ‘ êµ¬í˜„í•´ì•¼í•œë‹¤.
"""

def fit(data_loader, epochs):
  for epoch in range(epochs):
    now = time.time()
    avg_loss = 0
    total_batch = len(data_loader)

    for i, (batch_images, batch_labels) in enumerate(data_loader):

      X = batch_images.to(device)  # [-1, 1, 28, 28]

      # forward ë‹¨ê³„
      # 1. input dataë¥¼ ëª¨ë¸ì— í†µê³¼ì‹œí‚µë‹ˆë‹¤.
      # 2. lossë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
      Y_prediction = ae(X)
      loss = criterion(Y_prediction, X)

      # bacward ë‹¨ê³„
      # 1. backprop ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— ë³€í™”ë„ë¥¼ 0ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
      # 2. ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•œ ì†ì‹¤ì˜ ë³€í™”ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
      # 3. step í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë©´ ë§¤ê°œë³€ìˆ˜ê°€ ê°±ì‹ ë©ë‹ˆë‹¤.
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      avg_loss += loss / total_batch

    print("[Epoch: {:>4}] \t loss = {:.4f} \t time = {:.4f}"
          .format(epoch + 1, avg_loss.data, time.time()-now))

  print("Learning Finished!")

"""fit í•¨ìˆ˜ ì‹¤í–‰"""

fit(train_loader, num_epochs)

"""### íŠ¸ë ˆì´ë‹ì…‹ì„ ì´ìš©í•´ í•™ìŠµ í›„ ê²°ê³¼ ì‹œê°í™”
í•™ìŠµì´ ëë‚œ autoencoderì— ëŒ€í•´ train_datasetì— ëŒ€í•œ ê²°ê³¼ ì‹œê°í™”
"""

import matplotlib.pyplot as plt
from torchvision.transforms.functional import to_pil_image
import ipywidgets as widgets

def train_dataset_imshow(idx):
  (image, label) = train_dataset[idx]
  print('GT label:', label)

  X = torch.unsqueeze(image, 0).to(device) # batch size = 1
  Y_pred = ae(X)

  input_img  = to_pil_image(X.squeeze())
  output_img = to_pil_image(Y_pred.squeeze())

  plt.subplot(121)
  plt.imshow(input_img, cmap='gray')

  plt.subplot(122)
  plt.imshow(output_img, cmap='gray')

  plt.show()

widgets.interact(train_dataset_imshow, idx=widgets.IntSlider(min=0, max=len(train_dataset)-1, continuous_update=False))

import matplotlib.pyplot as plt
from torchvision.transforms.functional import to_pil_image
import ipywidgets as widgets

def train_dataset_imshow(idx):
  (image, label) = train_dataset[idx]
  print('GT label:', label)

  X = torch.unsqueeze(image, 0).to(device) # batch size = 1
  Y_pred = ae(X)

  input_img  = to_pil_image(X.squeeze())
  output_img = to_pil_image(Y_pred.squeeze())

  plt.subplot(121)
  plt.imshow(input_img, cmap='gray')

  plt.subplot(122)
  plt.imshow(output_img, cmap='gray')

  plt.show()

widgets.interact(train_dataset_imshow, idx=widgets.IntSlider(min=0, max=len(train_dataset)-1, continuous_update=False))

"""# ì¸ì½”ë” / ë””ì½”ë” ëª¨ë¸ì„ ê°ê° ë”°ë¡œ í•¨ìˆ˜ë¡œì„œ í™œìš©í•˜ê¸°
ì˜¤í† ì¸ì½”ë” ë„¤íŠ¸ì› ì „ì²´ê°€ ì•„ë‹Œ `enc()` ë¶€ë¶„ê³¼ `dec()` ë¶€ë¶„ì„ ê°ê° ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.
* íŠ¹ì • ì˜ˆì œì— ëŒ€í•œ ì¸ì½”ë”© ê²°ê³¼ì™€ ë””ì½”ë”© ê²°ê³¼ë¥¼ ë”°ë¡œ í™•ì¸í•œë‹¤.
"""

import matplotlib.pyplot as plt
from torchvision.transforms.functional import to_pil_image

idx = 128

(image, label) = test_dataset[idx]
print('GT label:', label)

### ì•„ë˜ì—ì„œ ae()ê°€ ì‚¬ìš©ë˜ì§€ ì•Šê³ , enc()ì™€ dec()ê°€ ì‚¬ìš©ë˜ì—ˆìŒì— ì£¼ëª©
X      = torch.unsqueeze(image, 0).to(device) # batch size = 1
z      = encoder(X)   # enc()ë§Œ ì‚¬ìš©í•´ ì…ë ¥ ì˜ìƒì„ ì¸ì½”ë”©í•´ **latent code z**ë¥¼ êµ¬í•¨
Y_pred = dec(z)   # dec()ë§Œ ì‚¬ìš©í•´ latent code zë¥¼ ë””ì½”ë”©í•´ ì¶œë ¥ ì˜ìƒ Y_predë¥¼ êµ¬í•¨

print("latent code z: ", z)

input_img  = to_pil_image(X.squeeze())
output_img = to_pil_image(Y_pred.squeeze())

plt.subplot(121)
plt.imshow(input_img, cmap='gray')

plt.subplot(122)
plt.imshow(output_img, cmap='gray')

"""ì¸ì½”ë”© ê²°ê³¼ì™€ ìœ ì‚¬í•œ ì¢Œí‘œê°’ì„ ë””ì½”ë”©ì— ë³´ë‚´ë„ ìœ ì‚¬í•œ ê²°ê³¼ê°€ ë‚˜ì˜´ì„ í™•ì¸"""

import ipywidgets as widgets

u=widgets.FloatSlider(min=-10.0, max=10.0, orientation='horizontal')
v=widgets.FloatSlider(min=-10.0, max=10.0, orientation='vertical')

ui = widgets.HBox([u,v])

def z_test(u, v):
  z_test = np.array([[u,v]])

  print(z_test)

  z_test = torch.FloatTensor(z_test).to(device)
  img_gen = dec(z_test)

  img_gen = to_pil_image(img_gen.squeeze())

  plt.imshow(img_gen, cmap='gray')
  plt.show()

out = widgets.interactive_output(z_test, {'u': u, 'v': v})

display(ui, out)

"""## TODO
1. encoderë¥¼ ê±°ì³ ë‚˜ì˜¨ representation zë¥¼ *GT label ë³„ë¡œ ë‹¤ë¥¸ìƒ‰*ì„ ì£¼ì–´ **zì˜ ë¶„í¬ë¥¼ ê°€ì‹œí™”**í•œë‹¤.
2. zì˜ ë¶„í¬ë¥¼ ë³´ê³  encoderê°€ label ë³„ë¡œ discriminativeí•œ representationì„ ë§Œë“¤ì–´ë‚´ëŠ”ì§€ ì—¬ë¶€ë¥¼ í™•ì¸í•œë‹¤.
3. ë§Œì¼ discriminativeí•˜ì§€ ì•Šë‹¤ë©´, autoencoderê°€ discriminativeí•œ representation zë¥¼ í•™ìŠµí•˜ë„ë¡ zì˜ ì°¨ì›ì„ ë°”ê¿”ê°€ë©´ì„œ ì‹¤í—˜ì„ ì§„í–‰í•œë‹¤.
4. ê²°ê³¼ì— ëŒ€í•œ ë¶„ì„ì„ ì‘ì„±í•œë‹¤.

## ì¸ì½”ë”© ê²°ê³¼ ê°€ì‹œí™”
ì˜¤í† ì¸ì½”ë”ì˜ encoderê°€ ë§Œë“¤ì–´ ë‚´ëŠ” representationì¸ z ê°’ì„ ê°€ì‹œí™” í•œë‹¤.
"""

# MNIST ë°ì´í„°ì˜ latent code ê°€ì‹œí™”
import matplotlib.pyplot as plt

# 10ê°œì˜ color listë¥¼ ë§Œë“ ë‹¤.
colors = ['red', 'green', 'blue', 'orange', 'violet',
          'khaki', 'pink', 'lightsalmon', 'darkseagreen', 'cyan']

# í…ŒìŠ¤íŠ¸ì…‹ì˜ whole batchì— ëŒ€í•œ ê²°ê³¼ í™•ì¸ì„ ìœ„í•œ dataloader ì •ì˜
whole_test_loader = DataLoader(dataset=test_dataset,
                               batch_size=len(test_dataset),
                               shuffle=False)
whole_test_images, whole_test_labels = next(iter(whole_test_loader))

whole_test_images = whole_test_images.to(device)
whole_test_labels = whole_test_labels.to(device)

## TODO: whole_train_imagesì— ëŒ€í•œ ì¸ì½”ë”© í•¨ìˆ˜ enc()ë¥¼ ì´ìš©í•´ latent codes z êµ¬í•˜ê¸°
with torch.no_grad():
  z = encoder(whole_test_images)

# z ë°°ì—´ì„ ë ˆì´ë¸” ì¡°ê±´ì„ ì´ìš©í•´ ìŠ¬ë¼ì´ì‹±

# # TODO: ë ˆì´ë¸” ë³„ë¡œ ë‹¤ë¥¸ ìƒ‰ì„ ì´ìš©í•´ ê°€ì‹œí™”
for label in range(10):
  z_label = z[whole_test_labels==label]
  print(z_label.shape)
  plt.plot(z_label[:,0].detach().cpu().numpy(), z_label[:,1].detach().cpu().numpy(), marker = 'o', linestyle='', color = colors[label])

"""## TODO: ë””ì½”ë”ë¥¼ ì´ìš©í•œ Generative Model êµ¬ì„±
1. z ê³µê°„ì˜ ì„ì˜ì˜ ìœ„ì¹˜ë¥¼ samplingí•œ í›„, ì´ë¥¼ decoderì˜ ì…ë ¥ìœ¼ë¡œ ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ generative modelì„ êµ¬ì¶•í•œë‹¤.
2. ê²°ê³¼ë¡œ ë§Œë“¤ì–´ì§€ëŠ” ì´ë¯¸ì§€ëŠ” ì–´ë–¤ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ ë¶„ì„í•œë‹¤.
"""

## TODO
z = np.array([[-40, -20],
              [0, 60],
              [15, 0]
             ])

if use_cuda:
  z = torch.FloatTensor(z)
  z = z.to(device)
  result = dec(z).cuda()
else:
  z = torch.FloatTensor(z)
  result = dec(z)
print(z.shape)
print(result.shape)

"""ê²°ê³¼ ê°€ì‹œí™”"""

## TODO

# ë¡œë”©ëœ MNIST ë°ì´í„° ê°€ì‹œí™”
import matplotlib.pyplot as plt
from torchvision.transforms.functional import to_pil_image

#result[0 ~ 2]ëŠ” decoderë¡œë¶€í„° ìƒì„±ëœ ì´ë¯¸ì§€
result_img_0 = to_pil_image(result[0].squeeze())
result_img_1 = to_pil_image(result[1].squeeze())
result_img_2 = to_pil_image(result[2].squeeze())

plt.subplot(131)
plt.imshow(result_img_0, cmap='gray')
plt.subplot(132)
plt.imshow(result_img_1, cmap='gray')
plt.subplot(133)
plt.imshow(result_img_2, cmap='gray')

"""Decoderë¥¼ ì´ìš©í•œ generative modelì„ êµ¬ì„±í•˜ê¸° ìœ„í•´,
2ì°¨ì› latent space ìƒì˜ z ê³µê°„ì˜ ì„ì˜ì˜ ìœ„ì¹˜ë¥¼ sampling, decoderì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì˜€ë‹¤.
decoderë¥¼ í†µí•´ '7', '0', '3' ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆë‹¤.
ì´ë¯¸ì§€ëŠ” MNIST ì´ë¯¸ì§€ì™€ ê°™ì´ ì™œê³¡ëœ ë¶€ë¶„ ì—†ì´ ìˆ«ìë¡œì„œì˜ í˜•íƒœ ê·¸ëŒ€ë¡œ ì˜ ë³µì›ë˜ì—ˆë‹¤.

"""